# -*- coding: utf-8 -*-
"""Copy of Copy of Copy of Copy of rnst2 d0 finaaalPolyps_seg.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/12R6BegQdrV8VSZNC-cCQ7QbUmPb1440S
"""



from google.colab import drive
drive.mount('/content/drive')

!pip install tensorflow==2.7.0



!unzip hyper-kvasir-segmented-images.zip



#must run this
import os
import numpy as np
from matplotlib import pyplot as plt
from tensorflow.keras.optimizers import Adam
import tensorflow as tf
import cv2
from PIL import Image
from keras import backend, optimizers



image_directory = 'segmented-images/images/'
mask_directory = 'segmented-images/masks/'

SIZE = 256
image_dataset = []  
mask_dataset = []

images = os.listdir(image_directory)
for i, image_name in enumerate(sorted(images)):    
    if (image_name.split('.')[1] == 'jpg'):
        #print(image_directory+image_name)
        image = cv2.imread(image_directory+image_name, 1)
        image = Image.fromarray(image)
        image = image.resize((SIZE, SIZE))
        image_dataset.append(np.array(image))

masks = os.listdir(mask_directory)
for i, image_name in enumerate(sorted(masks)):
    if (image_name.split('.')[1] == 'jpg'):
        image = cv2.imread(mask_directory+image_name, 0)
        image = Image.fromarray(image)
        image = image.resize((SIZE, SIZE))
        mask_dataset.append(np.array(image))

image_dataset = np.array(image_dataset)/255.
mask_dataset = np.expand_dims((np.array(mask_dataset)),3) /255.

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(image_dataset, mask_dataset, test_size = 0.10, random_state = 2)

#Sanity check
import random
import numpy as np
image_number = random.randint(0, len(X_train))
plt.figure(figsize=(12, 6))
plt.subplot(121)
plt.imshow(np.reshape(X_train[image_number], (256, 256, 3)), cmap='gray')
plt.subplot(122)
plt.imshow(np.reshape(y_train[image_number], (256, 256)), cmap='gray')
plt.show()

IMG_HEIGHT = X_train.shape[1]
IMG_WIDTH  = X_train.shape[2]
IMG_CHANNELS = X_train.shape[3]
num_labels = 1 
input_shape = (IMG_HEIGHT,IMG_WIDTH,IMG_CHANNELS) 
batch_size = 8

from tensorflow.keras import models, layers, regularizers
from tensorflow.keras import backend as K

def dice_coef(y_true, y_pred):
    y_true_f = K.flatten(y_true)
    y_pred_f = K.flatten(y_pred)
    intersection = K.sum(y_true_f * y_pred_f)
    return (2.0 * intersection + 1.0) / (K.sum(y_true_f) + K.sum(y_pred_f) + 1.0)



def dice_coef_loss(y_true, y_pred):
    return -dice_coef(y_true, y_pred)

##MODEL CODE STARTS HERE. BELOW ARE MANY FUNCTIONS, CLASS of BLOCKS WILL BE USED WHILE COMPILING THE MODEL

#These are for Attresunet. These will change for other models

kernel_initializer="he_normal"


def repeat_elem(tensor, rep):
    

     return layers.Lambda(lambda x, repnum: K.repeat_elements(x, repnum, axis=3),
                          arguments={'repnum': rep})(tensor)


def res_conv_block(x, filter_size, size, dropout, batch_norm):
    

    conv = layers.Conv2D(size, (filter_size, filter_size), padding='same', kernel_initializer=kernel_initializer)(x)
    if batch_norm is True:
        conv = layers.BatchNormalization(axis=3)(conv)
    conv = layers.Activation('relu')(conv)
    
    conv = layers.Conv2D(size, (filter_size, filter_size), padding='same', kernel_initializer=kernel_initializer)(conv)
    if batch_norm is True:
        conv = layers.BatchNormalization(axis=3)(conv)

    if dropout > 0:
        conv = layers.Dropout(dropout)(conv)

    shortcut = layers.Conv2D(size, kernel_size=(1, 1), padding='same', kernel_initializer=kernel_initializer)(x)
    if batch_norm is True:
        shortcut = layers.BatchNormalization(axis=3)(shortcut)

    res_path = layers.add([shortcut, conv])
    res_path = layers.Activation('relu')(res_path)   
    return res_path

def gating_signal(input, out_size, batch_norm):

    x = layers.Conv2D(out_size, (1, 1), padding='same', kernel_initializer=kernel_initializer)(input)
    if batch_norm:
        x = layers.BatchNormalization()(x)
    x = layers.Activation('relu')(x)
    return x

def attention_block(x, gating, inter_shape):
    shape_x = K.int_shape(x)
    shape_g = K.int_shape(gating)


    theta_x = layers.Conv2D(inter_shape, (2, 2), strides=(2, 2), padding='same', kernel_initializer=kernel_initializer)(x)  # 16
    shape_theta_x = K.int_shape(theta_x)

    phi_g = layers.Conv2D(inter_shape, (1, 1), padding='same', kernel_initializer=kernel_initializer)(gating)
    upsample_g = layers.Conv2DTranspose(inter_shape, (3, 3),
                                 strides=(shape_theta_x[1] // shape_g[1], shape_theta_x[2] // shape_g[2]),
                                 padding='same', kernel_initializer=kernel_initializer)(phi_g)  # 16

    concat_xg = layers.add([upsample_g, theta_x])
    act_xg = layers.Activation('relu')(concat_xg)
    psi = layers.Conv2D(1, (1, 1), padding='same', kernel_initializer=kernel_initializer)(act_xg)
    sigmoid_xg = layers.Activation('sigmoid')(psi)
    shape_sigmoid = K.int_shape(sigmoid_xg)
    upsample_psi = layers.UpSampling2D(size=(shape_x[1] // shape_sigmoid[1], shape_x[2] // shape_sigmoid[2]))(sigmoid_xg)  # 32

    upsample_psi = repeat_elem(upsample_psi, shape_x[3])

    y = layers.multiply([upsample_psi, x])

    result = layers.Conv2D(shape_x[3], (1, 1), padding='same', kernel_initializer=kernel_initializer)(y)
    result_bn = layers.BatchNormalization()(result)
    return result_bn

def Attention_ResUNet(input_shape, NUM_CLASSES=1, dropout_rate=0, batch_norm=True):
  
    FILTER_NUM = 64 # number of basic filters for the first layer
    FILTER_SIZE = 3 # size of the convolutional filter
    UP_SAMP_SIZE = 2 # size of upsampling filters
    # input data
    # dimension of the image depth
    inputs = layers.Input(input_shape, dtype=tf.float32)
    axis = 3

    # Downsampling layers
    # DownRes 1, double residual convolution + pooling
    conv_128 = res_conv_block(inputs, FILTER_SIZE, FILTER_NUM, dropout_rate, batch_norm)
    pool_64 = layers.MaxPooling2D(pool_size=(2,2))(conv_128)
    # DownRes 2
    conv_64 = res_conv_block(pool_64, FILTER_SIZE, 2*FILTER_NUM, dropout_rate, batch_norm)
    pool_32 = layers.MaxPooling2D(pool_size=(2,2))(conv_64)
    # DownRes 3
    conv_32 = res_conv_block(pool_32, FILTER_SIZE, 4*FILTER_NUM, dropout_rate, batch_norm)
    pool_16 = layers.MaxPooling2D(pool_size=(2,2))(conv_32)
    # DownRes 4
    conv_16 = res_conv_block(pool_16, FILTER_SIZE, 8*FILTER_NUM, dropout_rate, batch_norm)
    pool_8 = layers.MaxPooling2D(pool_size=(2,2))(conv_16)
    # DownRes 5, convolution only
    conv_8 = res_conv_block(pool_8, FILTER_SIZE, 16*FILTER_NUM, dropout_rate, batch_norm)

    # Upsampling layers
    # UpRes 6, attention gated concatenation + upsampling + double residual convolution
    gating_16 = gating_signal(conv_8, 8*FILTER_NUM, batch_norm)
    att_16 = attention_block(conv_16, gating_16, 8*FILTER_NUM)
    up_16 = layers.UpSampling2D(size=(UP_SAMP_SIZE, UP_SAMP_SIZE), data_format="channels_last")(conv_8)
    up_16 = layers.concatenate([up_16, att_16], axis=axis)
    up_conv_16 = res_conv_block(up_16, FILTER_SIZE, 8*FILTER_NUM, dropout_rate, batch_norm)
    # UpRes 7
    gating_32 = gating_signal(up_conv_16, 4*FILTER_NUM, batch_norm)
    att_32 = attention_block(conv_32, gating_32, 4*FILTER_NUM)
    up_32 = layers.UpSampling2D(size=(UP_SAMP_SIZE, UP_SAMP_SIZE), data_format="channels_last")(up_conv_16)
    up_32 = layers.concatenate([up_32, att_32], axis=axis)
    up_conv_32 = res_conv_block(up_32, FILTER_SIZE, 4*FILTER_NUM, dropout_rate, batch_norm)
    # UpRes 8
    gating_64 = gating_signal(up_conv_32, 2*FILTER_NUM, batch_norm)
    att_64 = attention_block(conv_64, gating_64, 2*FILTER_NUM)
    up_64 = layers.UpSampling2D(size=(UP_SAMP_SIZE, UP_SAMP_SIZE), data_format="channels_last")(up_conv_32)
    up_64 = layers.concatenate([up_64, att_64], axis=axis)
    up_conv_64 = res_conv_block(up_64, FILTER_SIZE, 2*FILTER_NUM, dropout_rate, batch_norm)
    # UpRes 9
    gating_128 = gating_signal(up_conv_64, FILTER_NUM, batch_norm)
    att_128 = attention_block(conv_128, gating_128, FILTER_NUM)
    up_128 = layers.UpSampling2D(size=(UP_SAMP_SIZE, UP_SAMP_SIZE), data_format="channels_last")(up_conv_64)
    up_128 = layers.concatenate([up_128, att_128], axis=axis)
    up_conv_128 = res_conv_block(up_128, FILTER_SIZE, FILTER_NUM, dropout_rate, batch_norm)

    # 1*1 convolutional layers
    
    conv_final = layers.Conv2D(NUM_CLASSES, kernel_size=(1,1), kernel_initializer=kernel_initializer)(up_conv_128)
    conv_final = layers.BatchNormalization(axis=axis)(conv_final)
    conv_final = layers.Activation('sigmoid')(conv_final)  #Change to softmax for multichannel

    # Model integration
    model = models.Model(inputs, conv_final, name="AttentionResUNet")
    return model



!pip install focal-loss
from focal_loss import BinaryFocalLoss

att_res_unet_model = Attention_ResUNet(input_shape)

att_res_unet_model.compile(optimizer=Adam(lr = 0.01), loss=BinaryFocalLoss(gamma=2), metrics=['accuracy', jacard_coef, dice_coef, jacard_coef_loss, dice_coef_loss])


#att_res_unet_model.compile(optimizer=Adam(lr = 1e-3), loss='binary_crossentropy', metrics=['accuracy',jacard_coef])

print(att_res_unet_model.summary())



model_path = "/content/drive/MyDrive/d5-3_21nov.hdf5"

att_res_unet_model = tf.keras.models.load_model(model_path, compile=False)

att_res_unet_model.compile(optimizer=Adam(lr = 0.01), loss=BinaryFocalLoss(gamma=2), metrics=['accuracy', dice_coef, dice_coef_loss])

att_res_unet_model.summary()

results = att_res_unet_model.evaluate(X_test, y_test, batch_size=8)

from tensorflow.keras.callbacks import LearningRateScheduler
epochs=85

def scheduler(epoch,lr):
  if epoch <=45:
  #  return lr
  # elif 15 < epoch <= 35:
  #   return 0.001
  # elif 35 < epoch <= 60:
    return 0.01
  else:
    return 0.01


lr =0.01
for i in range(epochs):
  lr = scheduler(i,lr)
  print(i, lr)

checkpointer = tf.keras.callbacks.ModelCheckpoint('/content/drive/MyDrive/d6_2_21novcheck.hdf5', monitor='val_dice_coef_loss', verbose=1, save_best_only=True)
lr_rate = tf.keras.callbacks.LearningRateScheduler(scheduler)
callbacks_list = [checkpointer,lr_rate]

att_res_unet_history = att_res_unet_model.fit(X_train, y_train, 
                    verbose=1,
                    batch_size = 12,
                    validation_data=(X_test, y_test), 
                    shuffle=True,
                    epochs=125,
                    callbacks=callbacks_list,
                    )

att_res_unet_model.save('/content/drive/MyDrive/d6_2_21nov.hdf5') 


import pandas as pd 
att_res_unet_history_df = pd.DataFrame(att_res_unet_history.history) 

with open('/content/drive/MyDrive/d6_2_21nov_history_df.csv', mode='w') as f:
    att_res_unet_history_df.to_csv(f) 


history = att_res_unet_history

loss = history.history['loss']
val_loss = history.history['val_loss']
epochs = range(1, len(loss) + 1)
plt.plot(epochs, loss, color='blue', label='Training loss')
plt.plot(epochs, val_loss, color='orange', label='Validation loss')
plt.title('Training and validation loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.show()

acc = history.history['accuracy']
val_acc = history.history['val_accuracy']
plt.plot(epochs, acc, color='blue', label='Training accuracy')
plt.plot(epochs, val_acc, color='orange', label='Validation accuracy')
plt.title('Training and validation accuracy')
plt.xlabel('Epochs')
plt.ylabel('accuracy')
plt.legend()
plt.show()


dice = history.history['dice_coef']
val_dice = history.history['val_dice_coef']

plt.plot(epochs, dice, color='blue', label='Training dice')
plt.plot(epochs, val_dice, color='orange', label='Validation dice')
plt.title('Training and validation dice')
plt.xlabel('Epochs')
plt.ylabel('dice')
plt.legend()
plt.show()

model = att_res_unet_model



import random
test_img_number = random.randint(0, X_test.shape[0]-1)
test_img = X_test[test_img_number]
ground_truth=y_test[test_img_number]

test_img_input=np.expand_dims(test_img, 0)
prediction = (model.predict(test_img_input)[0,:,:,0] > 0.5).astype(np.uint8)


plt.figure(figsize=(16, 8))
plt.subplot(231)
plt.title('Input Image')
plt.imshow(test_img, cmap='gray')
plt.subplot(232)
plt.title('Ground Truth')
plt.imshow(ground_truth[:,:,0], cmap='gray')
plt.subplot(233)
plt.title('Output Segmentated Image ')
plt.imshow(prediction, cmap='gray')
plt.show()


from tensorflow.keras.metrics import MeanIoU
from tensorflow.keras import backend as K

n_classes = 2
IOU_keras = MeanIoU(num_classes=n_classes)  
IOU_keras.update_state(ground_truth[:,:,0], prediction)
iou = IOU_keras.result().numpy()

y_true = ground_truth
y_pred = prediction

m = tf.keras.metrics.Precision()
m.update_state(y_true, y_pred)
precision = m.result().numpy()

m2 = tf.keras.metrics.Recall()
m2.update_state(y_true, y_pred)
recall = m2.result().numpy()

m3 = tf.keras.metrics.Accuracy()
m3.update_state(y_true, y_pred)
accuracy = m3.result().numpy()

f1= 2*((precision*recall)/(precision+recall))


ground_truth = ground_truth.astype('float32')
prediction = prediction.astype('float32')
dice=dice_coef(ground_truth, prediction).numpy()

print("iou= ", iou)
print("dice= ",dice)
print("accuracy= ",accuracy)
print('precision:',precision)
print('recall:', recall)
print('f1', f1)

import pandas as pd

IoU_values = []
dice_values = []
precision_values = []
recall_values = []
f1_values = []
accuracy_values = []

for img in range(0, X_test.shape[0]):
    temp_img = X_test[img]
    ground_truth=y_test[img]
    temp_img_input=np.expand_dims(temp_img, 0)
    prediction = (model.predict(temp_img_input)[0,:,:,0] > 0.5).astype(np.uint8)

    plt.figure(figsize=(12, 6))
    plt.subplot(231)
    plt.title('Input Image')
    plt.imshow(temp_img, cmap='gray')
    plt.subplot(232)
    plt.title('Ground Truth')
    plt.imshow(ground_truth[:,:,0], cmap='gray')
    plt.subplot(233)
    plt.title('Output Segmented Image')
    plt.imshow(prediction, cmap='gray')
    plt.show()
    
    IoU = MeanIoU(num_classes=n_classes)
    IoU.update_state(ground_truth[:,:,0], prediction)
    IoU = IoU.result().numpy()
    IoU_values.append(IoU)

    ground_truth1 = ground_truth.astype('float32')
    prediction1 = prediction.astype('float32')
    dice = dice_coef(ground_truth1, prediction1).numpy()
    dice_values.append(dice)



    y_true = ground_truth
    y_pred = prediction

    m = tf.keras.metrics.Precision()
    m.update_state(y_true, y_pred)
    precision = m.result().numpy()
    precision_values.append(precision)

    m2 = tf.keras.metrics.Recall()
    m2.update_state(y_true, y_pred)
    recall = m2.result().numpy()
    recall_values.append(recall)

    m3 = tf.keras.metrics.Accuracy()
    m3.update_state(y_true, y_pred)
    accuracy = m3.result().numpy()
    accuracy_values.append(accuracy)

    f1= 2*((precision*recall)/(precision+recall))
    f1_values.append(f1)

   

    print("iou= ", IoU)
    print("dice= ",dice)
    print("accuracy= ",accuracy)
    print('precision:',precision)
    print('recall:', recall)
    print('f1', f1)

df = pd.DataFrame(IoU_values, columns=["IoU"])
df = df[df.IoU != 1.0]    
mean_IoU = df.mean().values

df2 = pd.DataFrame(dice_values, columns=["dice"])
df2 = df2[df2.dice != 1.0]    
mean_dice = df2.mean().values

df3 = pd.DataFrame(accuracy_values, columns=["accuracy"])
df3 = df3[df3.accuracy != 1.0]    
mean_accuracy = df3.mean().values

df4 = pd.DataFrame(precision_values, columns=["precision"])
df4 = df4[df4.precision != 1.0]    
mean_precision = df4.mean().values

df5 = pd.DataFrame(recall_values, columns=["recall"])
df5 = df5[df5.recall != 1.0]    
mean_recall = df5.mean().values

df6 = pd.DataFrame(f1_values, columns=["f1"])
df6 = df6[df6.f1 != 1.0]    
mean_f1 = df6.mean().values

print("Mean IoU on 10% test is: ", mean_IoU)    
print("Mean dice  on 10% test is: ", mean_dice)  
print("Mean accuracy  on 10% test is: ", mean_accuracy)  
print("Mean precision on 10% test is: ", mean_precision)    
print("Mean recall  on 10% test is: ", mean_recall)  
print("Mean f1 on 10% test  is: ", mean_f1)

!unzip unseen.zip

test_seg_image = 'unseen/images/'
test_seg_mask = 'unseen/masks/'

SIZE = 256
test_image_dataset = []  
test_mask_dataset = []

images = os.listdir(test_seg_image)
for i, image_name in enumerate(sorted(images)):    
    if (image_name.split('.')[1] == 'jpg'):
      image = cv2.imread(test_seg_image+image_name, 1)
      image = Image.fromarray(image)
      image = image.resize((SIZE, SIZE))
      test_image_dataset.append(np.array(image))

filenames = []
files = os.listdir(test_seg_image)
for i, image_name in enumerate(sorted(files)):    
    if (image_name.split('.')[1] == 'jpg'):
      filenames.append(image_name)
      print(image_name)

masks = os.listdir(test_seg_mask)
for i, image_name in enumerate(sorted(masks)):
    if (image_name.split('.')[1] == 'png'):
        image = cv2.imread(test_seg_mask+image_name, 0)
        image = Image.fromarray(image)
        image = image.resize((SIZE, SIZE))
        test_mask_dataset.append(np.array(image))

test_image_dataset = np.array(test_image_dataset)/255.
test_mask_dataset = np.expand_dims((np.array(test_mask_dataset)),3) /255.

#Sanity check
import random
import numpy as np
image_number = random.randint(0, len(test_image_dataset))
plt.figure(figsize=(12, 6))
plt.subplot(121)
plt.imshow(np.reshape(test_image_dataset[image_number], (256, 256, 3)), cmap='gray')
plt.subplot(122)
plt.imshow(np.reshape(test_mask_dataset[image_number], (256, 256)), cmap='gray')
plt.show()

import random
test_img_number = random.randint(0, test_image_dataset.shape[0]-1)
print(filenames[test_img_number])
test_img = test_image_dataset[test_img_number]
ground_truth=test_mask_dataset[test_img_number]

test_img_input=np.expand_dims(test_img, 0)
prediction = (model.predict(test_img_input)[0,:,:,0] > 0.5).astype(np.uint8)


plt.figure(figsize=(16, 8))
plt.subplot(231)
plt.title('Input Image')
plt.imshow(test_img, cmap='gray')
plt.subplot(232)
plt.title('Ground Truth')
plt.imshow(ground_truth[:,:,0], cmap='gray')
plt.subplot(233)
plt.title('Output Segmented Image')
plt.imshow(prediction, cmap='gray')
plt.show()


from tensorflow.keras.metrics import MeanIoU
from tensorflow.keras import backend as K

n_classes = 2
IOU_keras = MeanIoU(num_classes=n_classes)  
IOU_keras.update_state(ground_truth[:,:,0], prediction)
iou = IOU_keras.result().numpy()

y_true = ground_truth
y_pred = prediction

m = tf.keras.metrics.Precision()
m.update_state(y_true, y_pred)
precision = m.result().numpy()

m2 = tf.keras.metrics.Recall()
m2.update_state(y_true, y_pred)
recall = m2.result().numpy()

m3 = tf.keras.metrics.Accuracy()
m3.update_state(y_true, y_pred)
accuracy = m3.result().numpy()

f1= 2*((precision*recall)/(precision+recall))


ground_truth = ground_truth.astype('float32')
prediction = prediction.astype('float32')
dice=dice_coef(ground_truth, prediction).numpy()

print("iou= ", iou)
print("dice= ",dice)
print("accuracy= ",accuracy)
print('precision:',precision)
print('recall:', recall)
print('f1', f1)

import pandas as pd

IoU_values = []
dice_values = []
precision_values = []
recall_values = []
f1_values = []
accuracy_values = []

for img in range(0, test_image_dataset.shape[0]):
    temp_img = test_image_dataset[img]
    ground_truth=test_mask_dataset[img]
    temp_img_input=np.expand_dims(temp_img, 0)
    prediction = (model.predict(temp_img_input)[0,:,:,0] > 0.5).astype(np.uint8)

    print(filenames[img])

    plt.figure(figsize=(16, 8))
    plt.subplot(231)
    plt.title('Input Image')
    plt.imshow(temp_img, cmap='gray')
    plt.subplot(232)
    plt.title('Ground Truth')
    plt.imshow(ground_truth[:,:,0], cmap='gray')
    plt.subplot(233)
    plt.title('Output Segmented Image')
    plt.imshow(prediction, cmap='gray')
    plt.savefig('/content/drive/MyDrive/Segmented/{}'.format(filenames[img]), bbox_inches="tight", pad_inches=0.5)
    plt.show()
    
    IoU = MeanIoU(num_classes=n_classes)
    IoU.update_state(ground_truth[:,:,0], prediction)
    IoU = IoU.result().numpy()
    IoU_values.append(IoU)

    ground_truth1 = ground_truth.astype('float32')
    prediction1 = prediction.astype('float32')
    dice = dice_coef(ground_truth1, prediction1).numpy()
    dice_values.append(dice)


    y_true = ground_truth
    y_pred = prediction

    m = tf.keras.metrics.Precision()
    m.update_state(y_true, y_pred)
    precision = m.result().numpy()
    precision_values.append(precision)

    m2 = tf.keras.metrics.Recall()
    m2.update_state(y_true, y_pred)
    recall = m2.result().numpy()
    recall_values.append(recall)

    m3 = tf.keras.metrics.Accuracy()
    m3.update_state(y_true, y_pred)
    accuracy = m3.result().numpy()
    accuracy_values.append(accuracy)

    f1= 2*((precision*recall)/(precision+recall))
    f1_values.append(f1)

   

    print("iou= ", IoU)
    print("dice= ",dice)
    print("accuracy= ",accuracy)
    print('precision:',precision)
    print('recall:', recall)
    print('f1', f1)


with open('/content/drive/MyDrive/dicelistd52.txt', 'w') as fp: 
    for item in dice_values:
      fp.write("%s\n" % item)
    print('Done dice txt')

with open('/content/drive/MyDrive/accuracylistd52.txt', 'w') as fp2: 
    for item in accuracy_values:
      fp2.write("%s\n" % item)
    print('Done accuracy txt')

df = pd.DataFrame(IoU_values, columns=["IoU"])
df = df[df.IoU != 1.0]    
mean_IoU = df.mean().values

df2 = pd.DataFrame(dice_values, columns=["dice"])
df2 = df2[df2.dice != 1.0]    
mean_dice = df2.mean().values

df3 = pd.DataFrame(accuracy_values, columns=["accuracy"])
df3 = df3[df3.accuracy != 1.0]    
mean_accuracy = df3.mean().values

df4 = pd.DataFrame(precision_values, columns=["precision"])
df4 = df4[df4.precision != 1.0]    
mean_precision = df4.mean().values

df5 = pd.DataFrame(recall_values, columns=["recall"])
df5 = df5[df5.recall != 1.0]    
mean_recall = df5.mean().values

df6 = pd.DataFrame(f1_values, columns=["f1"])
df6 = df6[df6.f1 != 1.0]    
mean_f1 = df6.mean().values

print("Mean IoU on unseen is: ", mean_IoU)    
print("Mean dice on unseen is: ", mean_dice)  
print("Mean accuracy on unseen is: ", mean_accuracy)  
print("Mean precision on unseen is: ", mean_precision)    
print("Mean recall on unseen is: ", mean_recall)  
print("Mean f1 on unseen  is: ", mean_f1)



